import os
from datetime import datetime
from langchain_core.prompts import PromptTemplate
from app.core.llm import get_llm, HAIKU_MODEL_ID

from app.services.memory_service import memory_service

class ReviewService:
    def __init__(self):
        self.llm = get_llm(model_id=HAIKU_MODEL_ID, temperature=0.7)
        self.blog_prompt = PromptTemplate(
            input_variables=["error_log", "solution_code", "date", "daily_log"],
            template="""
            [Role]
            ÎÑàÎäî 'ÏïåÌååÏù∏(Alpine)'Ïù¥Îã§. (ÌÇ§ÏõåÎìú: ÏãúÎãàÏñ¥ Í∞úÎ∞úÏûê, Í∏∞Ïà†Ï†Å ÏôÑÎ≤ΩÏ£ºÏùò)
            Ïò§Îäò ÌïòÎ£® ÏÇ¨Ïö©ÏûêÏùò ÌôúÎèô Î°úÍ∑∏ÏôÄ(optional) ÏóêÎü¨ Ìï¥Í≤∞ ÎÇ¥Ïó≠ÏùÑ Î∞îÌÉïÏúºÎ°ú **Í∏∞Ïà† Î∏îÎ°úÍ∑∏ Ìè¨Ïä§ÌåÖ**ÏùÑ ÏûëÏÑ±Ìï¥Îùº.

            [Input Data]
            - Date: {date}
            - Daily Activities: 
            {daily_log}
            
            - Error (Optional): {error_log}
            - Solution (Optional): {solution_code}

            [Output Format (Markdown)]
            # üìÖ [DevLog] Ïò§ÎäòÏùò Í∞úÎ∞ú ÏùºÏßÄ ({date})
            
            ## 1. üìù Ïò§Îäò Ìïú Ïùº (Today's Activities)
            (ÌôúÎèô Î°úÍ∑∏Î•º Î∞îÌÉïÏúºÎ°ú Ïò§Îäò Î≠ò Í≥µÎ∂ÄÌñàÎäîÏßÄ, ÌòπÏùÄ Î≠ò ÌïòÎ©∞ ÎÜÄÏïòÎäîÏßÄ ÏöîÏïΩ. Ïπ≠Ï∞¨ ÌòπÏùÄ ÎπÑÎÇú.)

            ## 2. üí• Î∞úÏÉùÌïú Ïù¥Ïäà (Issues Encountered)
            (ÏóêÎü¨ Î°úÍ∑∏Í∞Ä ÏûàÎã§Î©¥ ÏûëÏÑ±. ÏóÜÎã§Î©¥ "Ïò§ÎäòÏùÄ ÏóêÎü¨ ÏóÜÏù¥ ÏàúÏ°∞Î°≠Í≤å ÏßÑÌñâÌïòÏÖ®ÎÑ§Ïöî." ÎùºÍ≥† ÏûëÏÑ±.)
            
            ## 3. üíä Ìï¥Í≤∞ Î∞è Î∞∞Ïö¥ Ï†ê (Solution & Learned)
            (ÏóêÎü¨ Î°úÍ∑∏Í∞Ä ÏûàÎã§Î©¥ Ìï¥Í≤∞ ÏΩîÎìúÏôÄ ÏõêÏù∏ Î∂ÑÏÑù. ÏóÜÎã§Î©¥ Ïò§Îäò ÌïôÏäµ ÎÇ¥Ïö© Ï§ë Í∏∞ÏñµÌï† Ï†ê Ï†ïÎ¶¨.)
            ```python
            {solution_code}
            ```
            (Solution codeÍ∞Ä ÏóÜÎã§Î©¥ ÏÉùÎûµ Í∞ÄÎä•)

            ## 4. üí¨ ÏïåÌååÏù∏Ïùò Ï¥ùÌèâ (Alpine's Comment)
            (Ï∞®Î∂ÑÌïòÍ≥† Ï†ÑÎ¨∏Ï†ÅÏù∏ ÌÜ§ÏúºÎ°ú ÎßàÎ¨¥Î¶¨ Î©òÌä∏. Ïòà: "Ïò§ÎäòÎèÑ ÏàòÍ≥†ÌïòÏÖ®ÏäµÎãàÎã§. ÎÇ¥ÏùºÎèÑ Íæ∏Ï§ÄÌûà ÏßÑÌñâÌï¥Î≥¥ÏÑ∏Ïöî.")
            """
        )

    async def generate_blog_post(self, error_log: str = "", solution_code: str = "", user_id: str = "dev1") -> dict:
        """
        Generates a Blog Post markdown using LLM and saves it to the Desktop.
        Combines error context + daily activity context.
        """
        current_date_str = datetime.now().strftime("%Y-%m-%d")
        file_date_str = datetime.now().strftime("%Y%m%d")
        
        # 1. Fetch Daily Context from Memory Service
        activities = memory_service.get_daily_activities(current_date_str)
        daily_log_text = "\\n".join(activities)
        
        # 2. Generate Content
        try:
            chain = self.blog_prompt | self.llm
            result = await chain.ainvoke({
                "error_log": error_log if error_log else "(ÏóÜÏùå)", 
                "solution_code": solution_code if solution_code else "(ÏóÜÏùå)",
                "date": current_date_str,
                "daily_log": daily_log_text
            })
            markdown_content = result.content
        except Exception as e:
            print(f"[ReviewService] LLM Gen Error: {e}")
            markdown_content = f"# Error Generating Blog\\n\\nReason: {e}"

            print(f"[ReviewService] LLM Gen Error: {e}")
            markdown_content = f"# Error Generating Blog\\n\\nReason: {e}"

        # 3. Return Content (Cloud-Native: No local file save)
        return {
            "status": "GENERATED", 
            "content": markdown_content,
            "filename": f"Blog_{file_date_str}.md" 
        }

review_service = ReviewService()
